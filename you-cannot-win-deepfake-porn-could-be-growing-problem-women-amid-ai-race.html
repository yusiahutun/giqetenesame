<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=description content="And some have been offering users the opportunity to create their own images  essentially allowing anyone to turn whoever they wish into sexual fantasies without their consent, or use the technology to harm former partners."><meta name=author content="Reinaldo Massengill"><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/base16/css/style.css type=text/css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700" type=text/css><link rel=alternate href=./index.xml type=application/rss+xml title=ZestD><title>You cannot win: deepfake porn could be a growing problem for women amid AI race - ZestD</title></head><body><header><div class="container clearfix"><a class=path href=./index.html>[ZestD]</a>
<span class=caret># _</span><div class=right></div></div></header><div class=container><main role=main class=article><article class=single itemscope itemtype=http://schema.org/BlogPosting><div class=meta><span class=key>published on</span>
<span class=val><time itemprop=datePublished datetime=2024-08-07>August 07, 2024</time></span>
<span class=key>in</span>
<span class=val><a href=./categories/blog>blog</a></span></div><h1 class=headline itemprop=headline>You cannot win: deepfake porn could be a growing problem for women amid AI race</h1><section class=body itemprop=articleBody><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">And some have been offering users the opportunity to create their own images – essentially allowing anyone to turn whoever they wish into sexual fantasies without their consent, or use the technology to harm former partners.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">The problem, experts say, grew as it became easier to make sophisticated and visually compelling deepfakes. And they say it could get worse with the development of generative AI tools that are trained on billions of images from the internet and spit out novel content using existing data.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">“The reality is that the technology will continue to proliferate, will continue to develop and will continue to become sort of as easy as pushing the button,” said Adam Dodge, the founder of EndTAB, a group that provides trainings on technology-enabled abuse.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">“And as long as that happens, people will undoubtedly ... continue to misuse that technology to harm others, primarily through online sexual violence, deepfake pornography and fake nude images.”</p><h3 type=h3 data-qa=Component-Component class="e14khtrb0 css-17x7qa9 e793b7w1"><a class="link-text css-e0dnmk ef1hf1w0" href=# data-qa=BaseLink-renderAnchor-StyledAnchor><p><span data-qa=DigitalArchiveLink-TitleText class="css-66qo9a eeeqn932">Deepfake porn cases in Japan point to rise in sex-related cybercrime</span></p></a></h3><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Noelle Martin of Perth, Australia, has experienced that reality. The 28-year-old found deepfake porn of herself 10 years ago when out of curiosity one day she used Google to search an image of herself.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">To this day, Martin says she does not know who created the fake images, or videos of her engaging in sexual intercourse that she would later find. She suspects someone likely took a picture posted on her social media page or elsewhere and doctored it into porn.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Horrified, Martin contacted different websites for a number of years in an effort to get the images taken down. Some did not respond. Others took it down but she soon found it up again.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">“You cannot win,” Martin said. “This is something that is always going to be out there. It’s just like it’s forever ruined you.”</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">The more she spoke out, she said, the more the problem escalated. Some people even told her the way she dressed and posted images on social media contributed to the harassment – essentially blaming her for the images instead of the creators.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/cdn.i-scmp.com/sites/default/files/d8/images/canvas/2023/04/17/080ff383-be8a-49e9-b1f8-a3e02e57a0de_1126e908.jpg><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Eventually, Martin turned her attention towards legislation, advocating for a national law in Australia that would fine companies A$555,000 (US$370,706) if they do not comply with removal notices for such content from online safety regulators.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">But governing the internet is next to impossible when countries have their own laws for content that is sometimes made halfway around the world. Martin, currently a lawyer and legal researcher at the University of Western Australia, says she believes the problem has to be controlled through some sort of global solution.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">In the meantime, some AI models say they are already curbing access to explicit images.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">OpenAI says it removed explicit content from data used to train the image generating tool DALL-E, which limits the ability of users to create those types of images. The company also filters requests and says it blocks users from creating AI images of celebrities and prominent politicians.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Midjourney, another model, blocks the use of certain keywords and encourages users to flag problematic images to moderators.</p><h3 type=h3 data-qa=Component-Component class="e14khtrb0 css-17x7qa9 e793b7w1"><a class="link-text css-e0dnmk ef1hf1w0" href=# data-qa=BaseLink-renderAnchor-StyledAnchor><p><span data-qa=DigitalArchiveLink-TitleText class="css-66qo9a eeeqn932">Is South Korean the world’s first official deepfake candidate?</span></p></a></h3><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Meanwhile, the start-up Stability AI rolled out an update in November that removes the ability to create explicit images using its image generator Stable Diffusion. Those changes came following reports that some users were creating celebrity inspired nude pictures using the technology.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Stability AI spokesperson Motez Bishara said the filter uses a combination of keywords and other techniques like image recognition to detect nudity and returns a blurred image.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">But it is possible for users to manipulate the software and generate what they want since the company releases its code to the public. Bishara said Stability AI’s license “extends to third-party applications built on Stable Diffusion” and strictly prohibits “any misuse for illegal or immoral purposes”.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Some social media companies have also been tightening their rules to better protect their platforms against harmful materials.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">TikTok said last month all deepfakes or manipulated content that show realistic scenes must be labelled to indicate they’re fake or altered in some way, and that deepfakes of private figures and young people are no longer allowed.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/cdn.i-scmp.com/sites/default/files/d8/images/canvas/2023/04/17/9471a08e-49b0-4311-a055-ba04c2550207_ed2458dc.jpg><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Previously, the company had barred sexually explicit content and deepfakes that mislead viewers about real-world events and cause harm.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">The gaming platform Twitch also recently updated its policies around explicit deepfake images after a popular streamer named Atrioc was discovered to have a deepfake porn website open on his browser during a livestream in late January. The site featured phoney images of fellow Twitch streamers.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Twitch already prohibited explicit deepfakes, but now showing a glimpse of such content – even if it’s intended to express outrage – “will be removed and will result in an enforcement,” the company wrote in a blog post. And intentionally promoting, creating or sharing the material is grounds for an instant ban.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Other companies have also tried to ban deepfakes from their platforms, but keeping them off requires diligence.</p><h3 type=h3 data-qa=Component-Component class="e14khtrb0 css-17x7qa9 e793b7w1"><a class="link-text css-e0dnmk ef1hf1w0" href=# data-qa=BaseLink-renderAnchor-StyledAnchor><p><span data-qa=DigitalArchiveLink-TitleText class="css-66qo9a eeeqn932">EU tackles deepfakes with pressure on Big Tech like Google and Facebook</span></p></a></h3><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Apple and Google said recently they removed an app from their app stores that was running sexually suggestive deepfake videos of actresses to market the product.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Research into deepfake porn is not prevalent, but one report released in 2019 by the AI firm DeepTrace Labs found it was almost entirely weaponised against women and the most targeted individuals were Western actresses, followed by South Korean K-pop singers.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">The same app removed by Google and Apple had run ads on Meta’s platform, which includes Facebook, Instagram and Messenger.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Meta spokesperson Dani Lever said in a statement the company’s policy restricts both AI-generated and non-AI adult content and it has restricted the app’s page from advertising on its platforms.</p><img data-qa=BaseImage-handleRenderImage-StyledImage src=https://cdn.statically.io/img/cdn.i-scmp.com/sites/default/files/styles/wide_landscape/public/d8/video/thumbnail/2023/03/31/clean.jpg style=margin:auto;display:block;text-align:center><p data-qa=SCMPYoutubeVideoPreview-PreviewDuration class="css-dkee4u eaw92su1">01:20</p><p data-qa=SCMPYoutubeVideoPreview-PreviewTitle class="css-1ajvbe4 eaw92su2">Elon Musk joins experts in call for pause on AI development because of possible ‘risks to society’</p><p>Elon Musk joins experts in call for pause on AI development because of possible ‘risks to society’</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">In February, Meta, as well as adult sites like OnlyFans and Pornhub, began participating in an online tool, called Take It Down, that allows teens to report explicit images and videos of themselves from the internet.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">The reporting site works for regular images, and AI-generated content – which has become a growing concern for child safety groups.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">“When people ask our senior leadership what are the boulders coming down the hill that we’re worried about? The first is end-to-end encryption and what that means for child protection. And then second is AI and specifically deepfakes,” said Gavin Portnoy, a spokesperson for the National Center for Missing and Exploited Children, which operates the Take It Down tool.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">“We have not ... been able to formulate a direct response yet to it,” Portnoy said.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7tK%2FMqWWcp51ku6bD0miuqKqcmXyivtOimqWdX2h%2FcoOSb2hosZ%2BqeqStzaemrWWnnrtusMSep5%2BZm5p6sbvRp2Scp6WhsW6uxGaeq6ennruoec%2BrppuklaJ6uLvMnqVmmZ2esW6tyGapmpuV</p></section></article></main></div><footer><div class=container><span class=copyright>&copy; 2024 ZestD - <a rel=license href=http://creativecommons.org/licenses/by/4.0/>CC BY 4.0</a></span></div></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>